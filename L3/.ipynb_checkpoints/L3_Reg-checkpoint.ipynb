{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Гарри Поттер и предсказание зарплаты методом линейной регрессии\n",
    "\n",
    "Импортируем всё, что может понадобиться:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные об описаниях вакансий и соответствующих годовых зарплатах из файла salary-train.csv и посмотрите на структуру таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем предобработку текстов: приведем все буквы к нижнему регистру, а все небуквенные и нецифровые символы заменим на пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените TfidfVectorizer для преобразования текстов (колонка FullDescription) в веторы признаков. Оставьте только те слова, которые встречаются хотя бы в 5 объектах (параметр min_df при создании TfidVectorizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf_transformed_data = # переменная, в которую запишем полученную таблицу после преобразования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим пропуски в столбцах LocationNormalized и ContractTime на специальную строку ’nan’ и закодируем их методом one-hot, а затем объединим две полученные таблицы в общую таблицу признаков. Выберем также и вектор целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['LocationNormalized'].fillna('nan', inplace=True)\n",
    "data['ContractTime'].fillna('nan', inplace=True)\n",
    "one_hot_transformed_data = one_hot.fit_transform(data[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "X = hstack([tfidf_transformed_data, one_hot_transformed_data])\n",
    "y = data['SalaryNormalized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем обучать гребневую регрессию (более общий алгоритм линейной регрессии) - используем класс Ridge с параметром alpha=1 и random_state по вариантам. Постройте прогнозы для двух примеров из файла salary-test-mini.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните результат с результатами, полученными на деревьях различной глубины (DecisionTreeRegressor). Чему можно верить больше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <s>Гарри Поттер</s> Логистическая регрессия и проблема XOR\n",
    "\n",
    "XOR - это логическая операция, которая возвращает 1, если аргументы не равны, и 0 в обратном случае. Если мы изобразим случайные данные разных классов по принципу XOR, то увидим, что линейно их никак не разделить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "\n",
    "# сгенерируем синтетические данные, \n",
    "variant = # вставьте ваш вариант\n",
    "rng = np.random.RandomState(variant)\n",
    "X = rng.randn(300, 2)\n",
    "y = np.logical_xor(X[:, 0] < 0, X[:, 1] < 0)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте классификатор логистической регрессии и обучите его на тестовой выборке\n",
    "classifier = \n",
    "\n",
    "\n",
    "# Построим график, который покажет, как обучилась логистическая регрессия.\n",
    "def plot_boundary(clf, X, y):\n",
    "    xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
    "                     np.linspace(-3, 3, 50))\n",
    "    Z = clf.predict_proba(np.vstack((xx.ravel(), yy.ravel())).T)[:, 1].reshape(xx.shape)\n",
    "    image = plt.imshow(Z, interpolation='nearest',\n",
    "                           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "                           aspect='auto', origin='lower', cmap=plt.cm.PuOr_r)\n",
    "    contours = plt.contour(xx, yy, Z, levels=[0], linewidths=2,\n",
    "                               linetypes='--')\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired)\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    plt.colorbar(image)\n",
    "    \n",
    "plot_boundary(classifier, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что работает так себе. Что если на вход подать не $x_1$ и $x_2$, а некоторые их полиномы?\n",
    "Преобразуем текущие признаки в 6 других: $1, x_1, x_2, x_1^2, x_1x_2$ и $x_2^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "new_classifier = Pipeline([('poly', PolynomialFeatures(degree=2)), ('logit', LogisticRegression())])\n",
    "\n",
    "# Обучите новый классификатор на тех же данных и посмотрим, как он себя ведет в исходном пространстве признаков.\n",
    "\n",
    "\n",
    "plot_boundary(new_classifier, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало лучше. Теперь создайте и обучите дерево с максимальной глубиной, равной четырем. Результат оказывается довольно похожим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = \n",
    "\n",
    "\n",
    "plot_boundary(tree, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем данные той же природы для проверки точности наших моделей. У какой модели score получился больше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = rng.randn(300, 2)\n",
    "y_test = np.logical_xor(X_test[:, 0] < 0, X_test[:, 1] < 0)\n",
    "# код"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
